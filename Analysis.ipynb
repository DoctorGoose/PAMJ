{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two empty columns to the patient DataFrame\n",
    "df_pat['Distance to nearest dispensary'] = ''\n",
    "df_pat['Zipcode of nearest dispensary'] = ''\n",
    "\n",
    "# Function to calculate distance using geopy\n",
    "def calculate_distance(row):\n",
    "    patient_coords = (row['Latitude'], row['Longitude'])\n",
    "    distances = df_dispo.apply(lambda x: distance(patient_coords, (x['Latitude'], x['Longitude'])).miles, axis=1)\n",
    "    nearest_disp_index = distances.idxmin()\n",
    "    nearest_disp_zipcode = df_dispo.loc[nearest_disp_index, 'Zipcode']\n",
    "    nearest_disp_distance = distances[nearest_disp_index]\n",
    "    return row.Index, nearest_disp_distance, nearest_disp_zipcode\n",
    "\n",
    "# Calculate nearest neighbor for each patient using parallel processing\n",
    "def process_patient(row):\n",
    "    nearest_distance, nearest_zipcode = calculate_distance(row)\n",
    "    return nearest_distance, nearest_zipcode\n",
    "\n",
    "# Number of threads to use\n",
    "num_threads = 12\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Process patients in parallel\n",
    "    results = executor.map(process_patient, df_pat.iterrows())\n",
    "\n",
    "    # Update the patient DataFrame with results\n",
    "    for idx, (nearest_distance, nearest_zipcode) in results:\n",
    "        df_pat.loc[idx, 'Distance to nearest dispensary'] = nearest_distance\n",
    "        df_pat.loc[idx, 'Zipcode of nearest dispensary'] = nearest_zipcode\n",
    "\n",
    "# Save the patient DataFrame to a CSV file\n",
    "df_pat.to_csv('Patient_Analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATEFP PLACEFP   PLACENS    GEOID          NAME              NAMELSAD LSAD  \\\n",
      "0      42   47560  01215231  4247560  Markleysburg  Markleysburg borough   21   \n",
      "1      42   37792  01215394  4237792         Jeddo         Jeddo borough   21   \n",
      "2      42   48480  01215187  4248480         Media         Media borough   21   \n",
      "3      42   76904  01215142  4276904    Titusville       Titusville city   25   \n",
      "4      42   04136  01215635  4204136   Barkeyville   Barkeyville borough   21   \n",
      "\n",
      "  CLASSFP PCICBSA PCINECTA  MTFCC FUNCSTAT    ALAND  AWATER     INTPTLAT  \\\n",
      "0      C5       N        N  G4110        A   777818       0  +39.7362744   \n",
      "1      C5       N        N  G4110        A   731074       0  +40.9903610   \n",
      "2      C5       N        N  G4110        A  1966413    8303  +39.9199958   \n",
      "3      C5       N        N  G4110        A  7513072       0  +41.6272796   \n",
      "4      C5       N        N  G4110        A  7996811       0  +41.1955437   \n",
      "\n",
      "       INTPTLON                                           geometry  \n",
      "0  -079.4517436  POLYGON ((-79.45659 39.72826, -79.45658 39.728...  \n",
      "1  -075.8960719  POLYGON ((-75.90092 40.99527, -75.90086 40.995...  \n",
      "2  -075.3880224  POLYGON ((-75.39968 39.91601, -75.39968 39.916...  \n",
      "3  -079.6698493  POLYGON ((-79.69915 41.63688, -79.69284 41.636...  \n",
      "4  -079.9821401  POLYGON ((-79.99967 41.20908, -79.99728 41.209...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doctorgoose/miniconda3/envs/PAMJ/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'zip_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m joined_data \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39msjoin(zip_code_boundaries, lat_long_data, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m, op\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcontains\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Step 4: Aggregate counts\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m heatmap_data \u001b[39m=\u001b[39m joined_data\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mzip_code\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcount()\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     17\u001b[0m \u001b[39m# Step 5: Plot the heatmap\u001b[39;00m\n\u001b[1;32m     18\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/PAMJ/lib/python3.11/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8403\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8404\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8405\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8406\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8407\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8408\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8409\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8410\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[1;32m   8411\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8412\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8413\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/PAMJ/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    966\u001b[0m         obj,\n\u001b[1;32m    967\u001b[0m         keys,\n\u001b[1;32m    968\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    969\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    970\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    971\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    972\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    973\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    976\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/PAMJ/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'zip_code'"
     ]
    }
   ],
   "source": [
    "# Step 1: Select lat and long columns from dataframe\n",
    "lat_long_data = df_dispo[['Latitude', 'Longitude']]\n",
    "\n",
    "# Convert to geodataframe with CRS EPSG 4269\n",
    "lat_long_data = gpd.GeoDataFrame(lat_long_data, geometry=gpd.points_from_xy(lat_long_data.Longitude, lat_long_data.Latitude), crs=4269)\n",
    "\n",
    "# Step 2: Load zip code boundary shapefile\n",
    "zip_code_boundaries = gpd.read_file('tl_2017_42_place/tl_2017_42_place.shp')\n",
    "print(zip_code_boundaries.head())\n",
    "\n",
    "# Step 3: Spatial join\n",
    "joined_data = gpd.sjoin(zip_code_boundaries, lat_long_data, how='inner', op='contains')\n",
    "\n",
    "# Step 4: Aggregate counts\n",
    "heatmap_data = joined_data.groupby('zip_code')['Latitude'].count().reset_index()\n",
    "\n",
    "# Step 5: Plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "zip_code_boundaries.plot(ax=ax, color='white', edgecolor='black')\n",
    "heatmap_data.plot(column='latitude', cmap='YlOrRd', linewidth=0.8, ax=ax, edgecolor='black', legend=True)\n",
    "plt.title('Heatmap of Latitude/Longitude Pairs by Zip Code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAMJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
